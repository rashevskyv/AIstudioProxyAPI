# AI Studio Proxy API Configuration File Example
# Copy this file to .env and modify configuration as needed

# =============================================================================
# Service Port Configuration
# =============================================================================

# FastAPI service port
PORT=2048

# GUI launcher default port configuration
DEFAULT_FASTAPI_PORT=2048
DEFAULT_CAMOUFOX_PORT=9222

# Streaming proxy service configuration
STREAM_PORT=3120
# Set to 0 to disable streaming proxy service

# =============================================================================
# Proxy Configuration
# =============================================================================

# HTTP/HTTPS proxy settings
# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890

# Unified proxy configuration (higher priority than HTTP_PROXY/HTTPS_PROXY)
UNIFIED_PROXY_CONFIG=http://127.0.0.1:7890

# Proxy bypass list (semicolon separated)
# NO_PROXY=localhost;127.0.0.1;*.local

# =============================================================================
# Logging Configuration
# =============================================================================

# Server log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
SERVER_LOG_LEVEL=INFO

# Whether to redirect print output to logs
SERVER_REDIRECT_PRINT=false

# Enable debug logs
DEBUG_LOGS_ENABLED=false

# Enable trace logs
TRACE_LOGS_ENABLED=false

# =============================================================================
# Authentication Configuration
# =============================================================================

# Auto-save authentication information
AUTO_SAVE_AUTH=false

# Authentication save timeout (seconds)
AUTH_SAVE_TIMEOUT=30

# Auto-confirm login
AUTO_CONFIRM_LOGIN=true

# =============================================================================
# Browser Configuration
# =============================================================================

# Camoufox WebSocket endpoint
# CAMOUFOX_WS_ENDPOINT=ws://127.0.0.1:9222

# Launch mode (normal, headless, virtual_display, direct_debug_no_browser)
LAUNCH_MODE=normal

# =============================================================================
# API Default Parameters Configuration
# =============================================================================

# Default temperature value (0.0-2.0)
DEFAULT_TEMPERATURE=1.0

# Default maximum output tokens
DEFAULT_MAX_OUTPUT_TOKENS=65536

# Default Top-P value (0.0-1.0)
DEFAULT_TOP_P=0.95

# Default stop sequences (JSON array format)
DEFAULT_STOP_SEQUENCES=["User:"]

# Whether to automatically open and use "URL Context" feature when processing requests
# For details about this tool feature, see: https://ai.google.dev/gemini-api/docs/url-context
ENABLE_URL_CONTEXT=false

# Whether to enable "Specify Thinking Budget" feature by default (true/false)
# When not enabled, the model will generally decide the thinking budget itself
# This value will be used when no reasoning_effort parameter is provided in the API request
ENABLE_THINKING_BUDGET=false

# Default value for "Specify Thinking Budget Amount" (tokens)
# This value will be used when no reasoning_effort parameter is provided in the API request
DEFAULT_THINKING_BUDGET=8192

# Whether to enable "Google Search" feature by default (true/false)
# When no tools parameter is provided in the API request, this setting will be used as the default switch state for Google Search
ENABLE_GOOGLE_SEARCH=false

# =============================================================================
# Timeout Configuration (milliseconds)
# =============================================================================

# Response completion total timeout
RESPONSE_COMPLETION_TIMEOUT=300000

# Initial wait time
INITIAL_WAIT_MS_BEFORE_POLLING=500

# Polling interval
POLLING_INTERVAL=300
POLLING_INTERVAL_STREAM=180

# Silence timeout
SILENCE_TIMEOUT_MS=60000

# Page operation timeout
POST_SPINNER_CHECK_DELAY_MS=500
FINAL_STATE_CHECK_TIMEOUT_MS=1500
POST_COMPLETION_BUFFER=700

# Clear chat related timeout
CLEAR_CHAT_VERIFY_TIMEOUT_MS=4000
CLEAR_CHAT_VERIFY_INTERVAL_MS=4000

# Click and clipboard operation timeout
CLICK_TIMEOUT_MS=3000
CLIPBOARD_READ_TIMEOUT_MS=3000

# Element wait timeout
WAIT_FOR_ELEMENT_TIMEOUT_MS=10000

# Stream related configuration
PSEUDO_STREAM_DELAY=0.01

# =============================================================================
# GUI Launcher Configuration
# =============================================================================

# GUI default proxy address
GUI_DEFAULT_PROXY_ADDRESS=http://127.0.0.1:7890

# GUI default streaming proxy port
GUI_DEFAULT_STREAM_PORT=3120

# GUI default Helper endpoint
GUI_DEFAULT_HELPER_ENDPOINT=

# =============================================================================
# Script Injection Configuration
# =============================================================================

# Whether to enable userscript injection feature (deprecated)
ENABLE_SCRIPT_INJECTION=false

# Userscript file path (relative to project root)
# Model data is directly parsed from this script file, no additional configuration file needed
USERSCRIPT_PATH=browser_utils/more_modles.js

# =============================================================================
# Other Configuration
# =============================================================================

# Model name
MODEL_NAME=AI-Studio_Proxy_API

# Chat completion ID prefix
CHAT_COMPLETION_ID_PREFIX=chatcmpl-

# Default fallback model ID
DEFAULT_FALLBACK_MODEL_ID=no model list

# Excluded models filename
EXCLUDED_MODELS_FILENAME=excluded_models.txt

# AI Studio URL pattern
AI_STUDIO_URL_PATTERN=aistudio.google.com/

# Model endpoint URL contains string
MODELS_ENDPOINT_URL_CONTAINS=MakerSuiteService/ListModels

# User input markers
USER_INPUT_START_MARKER_SERVER=__USER_INPUT_START__
USER_INPUT_END_MARKER_SERVER=__USER_INPUT_END__

# =============================================================================
# Stream Status Configuration
# =============================================================================

# Stream timeout log status configuration
STREAM_MAX_INITIAL_ERRORS=3
STREAM_WARNING_INTERVAL_AFTER_SUPPRESS=60.0
STREAM_SUPPRESS_DURATION_AFTER_INITIAL_BURST=400.0

# =============================================================================
# Conversation Mode Configuration
# =============================================================================

# Enable continuous conversation mode (true/false)
# When set to true, the program will not clear chat history before each request, allowing multi-round conversations
# When set to false, each request will be in a new chat session
ENABLE_CONTINUOUS_CHAT=false